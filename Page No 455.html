<html>

<head>

<title>This Is The Page No 454</title>

<style type="text/css">
body{
    text-align:center;
}

</style>

</head>

<body>

<p>o find significant and important vocabulary from within a natural language text docu-<br/>
ment. From the document-level analysis, it is possible to examine collections of docu-<br/>
ments. The methods used to do this include clustering and classification. Clustering is<br/>
the process of grouping documents with similar contents into dynamically generated<br/>
clusters. This is in contrast to text categorization, where the process is a bit more<br/>
involved. Here, samples of documents fitting into pre-determined “themes” or “catego-<br/>
ries” are fed into a “trainer,” which in turn generates a categorization schema. When the<br/>
documents to be analyzed are then fed into the categorizer, which incorporates the<br/>
schema previously produced, it will then assign documents to different categories based<br/>
on the taxonomy previously provided. These features are incorporated in programs such<br/>
as IBM’s Intelligent Miner for Text (Dorre, Gerstl, & Seiffert, 1999).</p>

<h2>DISTRIBUTED/COLLECTIVE DM</h2>

<p>One area of DM that is attracting a good amount of attention is distributed and<br/>
collective DM. Much of the DM that is being done currently focuses on a DB or data<br/>
warehouse of information that is physically located in one place. However, the situation<br/>
arises where information may be located in different places, or in different physical<br/>
locations. This is known generally as distributed-data mining (DDM). Therefore, the goal<br/>
is to effectively mine distributed data that are located in heterogeneous sites. DDM is<br/>
used to offer a different approach to traditional approaches to analysis, by using a<br/>
combination of localized data analysis together with a “global data model.” In more<br/>
specific terms, this is defined as performing local data analysis for generating partial data<br/>
models, and combining the local data models from different data sites in order to develop<br/>
the global model. This global model combines the results of the separate analyses. Often<br/>
the global model produced may become incorrect or ambiguous, especially if the data in<br/><br/>
different locations have different features or characteristics. This problem is especially<br/>
critical when the data in distributed sites are heterogeneous rather than homogeneous.<br/>
These heterogeneous data sets are known as vertically partitioned data sets. An<br/>
approach proposed by Kargupta, Park, Herschberger, and Johnson (2000) speaks of the<br/>
collective data-mining (CDM) approach, which provides a better approach to vertically<br/>
partitioned data sets using the notion of orthonormal basis functions, and computes the<br/>
basis coefficients to generate the global model of the data.</p>

<h2>UBIQUITOUS DM (UDM)</h2>

<p>The advent of laptops, palmtops, cell phones, and wearable computers is making<br/>
ubiquitous access to large quantity of data possible. Advanced analysis of data for<br/>
extracting useful knowledge is the next natural step in the world of ubiquitous computing.<br/>
However, there are challenges that exist for UDM. Human-computer interaction and data<br/>
management are challenging issues. Moreover, the sociological and psychological<br/>
aspects of the integration between DM technology and our lifestyle are yet to be<br/>
explored. The key issues to consider include theories of UDM, advanced algorithms for<br/>
mobile and distributed applications, data management issues, markup languages, and</p>

</body>

</html>